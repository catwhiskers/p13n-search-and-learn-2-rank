{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data \n",
    "* reference to https://www.kaggle.com/c/crowdflower-search-relevance\n",
    "* some codes reference to https://www.kaggle.com/abhishek/beating-the-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-19 16:28:32--  https://tinyurl.com/y6bg2kqn\n",
      "Resolving tinyurl.com (tinyurl.com)... 104.20.138.65, 104.20.139.65, 172.67.1.225, ...\n",
      "Connecting to tinyurl.com (tinyurl.com)|104.20.138.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://recommendation-demo-yianc.s3.us-east-1.amazonaws.com/crowdflower-search-relevance.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIATLORAEYMTX7JY4ER%2F20201019%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201019T124432Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=d76ef4b877cf4a9ebede0f0c47a68f4b15a5366942c7d6276f3798e91737cef8 [following]\n",
      "--2020-10-19 16:28:32--  https://recommendation-demo-yianc.s3.us-east-1.amazonaws.com/crowdflower-search-relevance.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIATLORAEYMTX7JY4ER%2F20201019%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201019T124432Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=d76ef4b877cf4a9ebede0f0c47a68f4b15a5366942c7d6276f3798e91737cef8\n",
      "Resolving recommendation-demo-yianc.s3.us-east-1.amazonaws.com (recommendation-demo-yianc.s3.us-east-1.amazonaws.com)... 52.217.13.32\n",
      "Connecting to recommendation-demo-yianc.s3.us-east-1.amazonaws.com (recommendation-demo-yianc.s3.us-east-1.amazonaws.com)|52.217.13.32|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6734649 (6.4M) [application/zip]\n",
      "Saving to: ‘crowdflower-search-relevance.zip’\n",
      "\n",
      "crowdflower-search- 100%[===================>]   6.42M  11.1MB/s    in 0.6s    \n",
      "\n",
      "2020-10-19 16:28:33 (11.1 MB/s) - ‘crowdflower-search-relevance.zip’ saved [6734649/6734649]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O  crowdflower-search-relevance.zip   https://tinyurl.com/y6bg2kqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  crowdflower-search-relevance.zip\n",
      "  inflating: sampleSubmission.csv.zip  \n",
      "  inflating: test.csv.zip            \n",
      "  inflating: train.csv.zip           \n",
      "Archive:  test.csv.zip\n",
      "  inflating: test.csv                \n",
      "Archive:  train.csv.zip\n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "rm -rf crowdflower\n",
    "mkdir crowdflower \n",
    "mv crowdflower-search-relevance.zip crowdflower/\n",
    "cd crowdflower\n",
    "unzip crowdflower-search-relevance.zip\n",
    "unzip test.csv.zip \n",
    "unzip train.csv.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Beating the Benchmark \n",
    "Search Results Relevance @ Kaggle\n",
    "__author__ : Abhishek\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, pipeline, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bridal shower decorations</td>\n",
       "      <td>Accent Pillow with Heart Design - Red/Black</td>\n",
       "      <td>Red satin accent pillow embroidered with a hea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>led christmas lights</td>\n",
       "      <td>Set of 10 Battery Operated Multi LED Train Chr...</td>\n",
       "      <td>Set of 10 Battery Operated Train Christmas Lig...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>projector</td>\n",
       "      <td>ViewSonic Pro8200 DLP Multimedia Projector</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>wine rack</td>\n",
       "      <td>Concept Housewares WR-44526 Solid-Wood Ceiling...</td>\n",
       "      <td>Like a silent and sturdy tree, the Southern En...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>light bulb</td>\n",
       "      <td>Wintergreen Lighting Christmas LED Light Bulb ...</td>\n",
       "      <td>WTGR1011\\nFeatures\\nNickel base, 60,000 averag...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      query  \\\n",
       "0   1  bridal shower decorations   \n",
       "1   2       led christmas lights   \n",
       "2   4                  projector   \n",
       "3   5                  wine rack   \n",
       "4   7                 light bulb   \n",
       "\n",
       "                                       product_title  \\\n",
       "0        Accent Pillow with Heart Design - Red/Black   \n",
       "1  Set of 10 Battery Operated Multi LED Train Chr...   \n",
       "2         ViewSonic Pro8200 DLP Multimedia Projector   \n",
       "3  Concept Housewares WR-44526 Solid-Wood Ceiling...   \n",
       "4  Wintergreen Lighting Christmas LED Light Bulb ...   \n",
       "\n",
       "                                 product_description  median_relevance  \\\n",
       "0  Red satin accent pillow embroidered with a hea...                 1   \n",
       "1  Set of 10 Battery Operated Train Christmas Lig...                 4   \n",
       "2                                                NaN                 4   \n",
       "3  Like a silent and sturdy tree, the Southern En...                 4   \n",
       "4  WTGR1011\\nFeatures\\nNickel base, 60,000 averag...                 2   \n",
       "\n",
       "   relevance_variance  \n",
       "0               0.000  \n",
       "1               0.000  \n",
       "2               0.471  \n",
       "3               0.000  \n",
       "4               0.471  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./crowdflower/train.csv')\n",
    "test = pd.read_csv('./crowdflower/test.csv')\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Bert Embedding to both Query and Result\n",
    "* Get the embedding (768 dim) for each word \n",
    "* Average the embedding as the sentence embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-embedding\n",
      "  Downloading bert_embedding-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting numpy==1.14.6\n",
      "  Downloading numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (13.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.8 MB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing==3.6.6\n",
      "  Downloading typing-3.6.6-py3-none-any.whl (25 kB)\n",
      "Collecting gluonnlp==0.6.0\n",
      "  Downloading gluonnlp-0.6.0.tar.gz (209 kB)\n",
      "\u001b[K     |████████████████████████████████| 209 kB 63.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mxnet==1.4.0\n",
      "  Downloading mxnet-1.4.0-py2.py3-none-manylinux1_x86_64.whl (29.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 29.6 MB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet==1.4.0->bert-embedding) (2.22.0)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2020.6.20)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gluonnlp: filename=gluonnlp-0.6.0-py3-none-any.whl size=259917 sha256=7b4bf87fe88f52191a6d157b5d4eb9a131250066f945925baef649ae244cb303\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/44/1b/6e/f9f9ab79b9892b7792be58ea33c03b504824e064c721b637f5\n",
      "Successfully built gluonnlp\n",
      "\u001b[31mERROR: numba 0.48.0 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: astropy 4.0 has requirement numpy>=1.16, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, typing, gluonnlp, graphviz, mxnet, bert-embedding\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.1\n",
      "    Uninstalling numpy-1.18.1:\n",
      "      Successfully uninstalled numpy-1.18.1\n",
      "Successfully installed bert-embedding-1.0.1 gluonnlp-0.6.0 graphviz-0.8.4 mxnet-1.4.0 numpy-1.14.6 typing-3.6.6\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting mxnet-cu100\n",
      "  Downloading mxnet_cu100-1.7.0-py2.py3-none-manylinux2014_x86_64.whl (827.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 827.8 MB 4.4 kB/s  eta 0:00:01   |█                               | 25.5 MB 3.9 MB/s eta 0:03:25\n",
      "\u001b[?25hCollecting numpy<2.0.0,>1.16.0\n",
      "  Downloading numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 62.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet-cu100) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet-cu100) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-cu100) (2020.6.20)\n",
      "\u001b[31mERROR: mxnet 1.4.0 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: bert-embedding 1.0.1 has requirement numpy==1.14.6, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, mxnet-cu100\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.14.6\n",
      "    Uninstalling numpy-1.14.6:\n",
      "      Successfully uninstalled numpy-1.14.6\n",
      "Successfully installed mxnet-cu100-1.7.0 numpy-1.19.2\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-embedding\n",
    "!pip install mxnet-cu100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.median_relevance.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip595faea2-329d-4a24-9690-929d612335a5 from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n",
      "0 1 0.54326254\n",
      "0 2 0.62364423\n",
      "1 2 0.4466143\n"
     ]
    }
   ],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "\n",
    "embedding = BertEmbedding()\n",
    "\n",
    "res = embedding(['welcome to the workshop!', 'how are you today?', 'the workshop is about to finish:)'])\n",
    "embeddings = [] \n",
    "for r in res: \n",
    "    embeddings.append(np.mean(r[1], axis=0)) \n",
    "    \n",
    "for i, e1 in enumerate(embeddings): \n",
    "    for j, e2 in enumerate(embeddings): \n",
    "        if j > i: \n",
    "            print(i, j, np.inner(e1,e2)/np.linalg.norm(e1)/np.linalg.norm(e2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from bert_embedding import BertEmbedding\n",
    "ctx = mx.gpu(0)\n",
    "embedding = BertEmbedding(ctx)\n",
    "\n",
    "def to_q_p_bert_embeddings(q_str_list, p_str_list): \n",
    "    reslist = []\n",
    "    queries = embedding(q_str_list)\n",
    "    titles = embedding(p_str_list)\n",
    "    index = 0 \n",
    "    for q, t in zip(queries, titles): \n",
    "        q_emb = np.mean(q[1], axis=0)\n",
    "        p_emb = np.mean(t[1], axis=0)\n",
    "        q_p_emb = np.concatenate((q_emb, p_emb), axis=0)\n",
    "        reslist.append(q_p_emb)\n",
    "        index += 1 \n",
    "    return pd.DataFrame(np.stack(reslist, axis=0))\n",
    "\n",
    "\n",
    "\n",
    "def df_to_q_p_bert_embeddings(df): \n",
    "    q_str_list = list(df.apply(lambda x:'%s ' % x['query'],axis=1))\n",
    "    p_str_list = list(df.apply(lambda x:'%s ' % x['product_title'],axis=1))\n",
    "    return to_q_p_bert_embeddings(q_str_list, p_str_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training data feature by bert\n",
    "traindata = df_to_q_p_bert_embeddings(train)\n",
    "testdata = df_to_q_p_bert_embeddings(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1526</th>\n",
       "      <th>1527</th>\n",
       "      <th>1528</th>\n",
       "      <th>1529</th>\n",
       "      <th>1530</th>\n",
       "      <th>1531</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.735250</td>\n",
       "      <td>0.018147</td>\n",
       "      <td>0.123991</td>\n",
       "      <td>-0.110519</td>\n",
       "      <td>-0.082966</td>\n",
       "      <td>-0.029868</td>\n",
       "      <td>0.325415</td>\n",
       "      <td>0.190573</td>\n",
       "      <td>-0.506424</td>\n",
       "      <td>0.108005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344477</td>\n",
       "      <td>-0.358536</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>-0.046444</td>\n",
       "      <td>0.453681</td>\n",
       "      <td>0.045681</td>\n",
       "      <td>0.094642</td>\n",
       "      <td>-0.271454</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>-0.427484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118757</td>\n",
       "      <td>0.322048</td>\n",
       "      <td>0.258831</td>\n",
       "      <td>-0.151294</td>\n",
       "      <td>0.782950</td>\n",
       "      <td>-0.509264</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.696682</td>\n",
       "      <td>-0.638701</td>\n",
       "      <td>0.014723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056819</td>\n",
       "      <td>-0.468251</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.077650</td>\n",
       "      <td>0.427598</td>\n",
       "      <td>-0.017002</td>\n",
       "      <td>-0.121644</td>\n",
       "      <td>0.026201</td>\n",
       "      <td>-0.086904</td>\n",
       "      <td>-0.005170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.261753</td>\n",
       "      <td>-0.447223</td>\n",
       "      <td>-0.073852</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>0.735644</td>\n",
       "      <td>0.087332</td>\n",
       "      <td>-0.426846</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>-0.233462</td>\n",
       "      <td>-0.406344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011183</td>\n",
       "      <td>0.146697</td>\n",
       "      <td>0.386955</td>\n",
       "      <td>-0.752387</td>\n",
       "      <td>0.566743</td>\n",
       "      <td>0.639849</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>-0.119964</td>\n",
       "      <td>-0.149333</td>\n",
       "      <td>-0.401775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.620772</td>\n",
       "      <td>-0.295450</td>\n",
       "      <td>-0.181161</td>\n",
       "      <td>0.142895</td>\n",
       "      <td>0.604595</td>\n",
       "      <td>-0.408538</td>\n",
       "      <td>-0.173805</td>\n",
       "      <td>-0.204155</td>\n",
       "      <td>0.087850</td>\n",
       "      <td>-0.154124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084784</td>\n",
       "      <td>-0.402696</td>\n",
       "      <td>0.335999</td>\n",
       "      <td>-0.345664</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>-0.184482</td>\n",
       "      <td>0.126904</td>\n",
       "      <td>0.152405</td>\n",
       "      <td>-0.270702</td>\n",
       "      <td>-0.046047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.249268</td>\n",
       "      <td>-0.102069</td>\n",
       "      <td>-0.103236</td>\n",
       "      <td>-0.244715</td>\n",
       "      <td>1.120806</td>\n",
       "      <td>0.144867</td>\n",
       "      <td>-0.723018</td>\n",
       "      <td>0.362883</td>\n",
       "      <td>-0.492101</td>\n",
       "      <td>-0.902789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004831</td>\n",
       "      <td>-0.546794</td>\n",
       "      <td>-0.029448</td>\n",
       "      <td>-0.016037</td>\n",
       "      <td>0.527882</td>\n",
       "      <td>-0.082519</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.086617</td>\n",
       "      <td>-0.282741</td>\n",
       "      <td>-0.214251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.735250  0.018147  0.123991 -0.110519 -0.082966 -0.029868  0.325415   \n",
       "1  0.118757  0.322048  0.258831 -0.151294  0.782950 -0.509264  0.005837   \n",
       "2 -0.261753 -0.447223 -0.073852 -0.004720  0.735644  0.087332 -0.426846   \n",
       "3  0.620772 -0.295450 -0.181161  0.142895  0.604595 -0.408538 -0.173805   \n",
       "4  0.249268 -0.102069 -0.103236 -0.244715  1.120806  0.144867 -0.723018   \n",
       "\n",
       "       7         8         9     ...      1526      1527      1528      1529  \\\n",
       "0  0.190573 -0.506424  0.108005  ...  0.344477 -0.358536  0.536474 -0.046444   \n",
       "1  0.696682 -0.638701  0.014723  ... -0.056819 -0.468251  0.022225  0.077650   \n",
       "2  0.029383 -0.233462 -0.406344  ...  0.011183  0.146697  0.386955 -0.752387   \n",
       "3 -0.204155  0.087850 -0.154124  ...  0.084784 -0.402696  0.335999 -0.345664   \n",
       "4  0.362883 -0.492101 -0.902789  ... -0.004831 -0.546794 -0.029448 -0.016037   \n",
       "\n",
       "       1530      1531      1532      1533      1534      1535  \n",
       "0  0.453681  0.045681  0.094642 -0.271454  0.115632 -0.427484  \n",
       "1  0.427598 -0.017002 -0.121644  0.026201 -0.086904 -0.005170  \n",
       "2  0.566743  0.639849  0.084125 -0.119964 -0.149333 -0.401775  \n",
       "3  0.337963 -0.184482  0.126904  0.152405 -0.270702 -0.046047  \n",
       "4  0.527882 -0.082519  0.014980  0.086617 -0.282741 -0.214251  \n",
       "\n",
       "[5 rows x 1536 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training by GBDT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "\t\t\t\t\t ('scl', scl),\n",
    "             \t     ('gbdt', gdbt_model)])\n",
    "param_grid = {'svd__n_components' : [200,400],\n",
    "              'gbdt__n_estimators': [200,400]}\n",
    "   \n",
    "quadratic_weighted_kappa_scorer = metrics.make_scorer(quadratic_weighted_kappa, greater_is_better = False)               \n",
    "#mse_scorer = metrics.make_scorer(mean_squared_error, greater_is_better = False)               \n",
    "model = GridSearchCV(estimator = clf, param_grid=param_grid, scoring=quadratic_weighted_kappa_scorer,\n",
    "                                      verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X=traindata \n",
    "\n",
    "svd = TruncatedSVD(n_components=400)\n",
    "    \n",
    "# Initialize the standard scaler \n",
    "scl = StandardScaler()\n",
    "    \n",
    "# We will use SVM here..\n",
    "gdbt_model = GradientBoostingClassifier(n_estimators=00)\n",
    "    \n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('scl', scl),\n",
    "                         ('gbdt', gdbt_model)])\n",
    "    \n",
    "model = clf\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Data Into Elastic Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_user=\"master_user\"\n",
    "master_user_password=\"master_user_password\"\n",
    "elastic_search_endpoint=\"elastic_search_endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pprint import pprint\n",
    "import boto3\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "def connectES(esEndPoint):\n",
    "    print ('Connecting to the ES Endpoint {0}'.format(esEndPoint))\n",
    "    try:\n",
    "        esClient = Elasticsearch(\n",
    "        hosts=[{'host': esEndPoint, 'port': 443}],\n",
    "        http_auth=(master_user, master_user_password),\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection)\n",
    "        return esClient\n",
    "    except Exception as E:\n",
    "        print(\"Unable to connect to {0}\".format(esEndPoint))\n",
    "        print(E)\n",
    "        exit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esClient = connectES(elastic_search_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexDocElement(esClient, response):\n",
    "    try:\n",
    "        retval = esClient.index(index='crowdflower', doc_type='crowdflower', body=response)\n",
    "    except Exception as E:\n",
    "        print(\"Doc not indexed\")\n",
    "        print(\"Error: \",E)\n",
    "        exit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([train, test])\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_index = all_df[[\"id\", \"product_title\"]]\n",
    "\n",
    "item_json = to_index.to_json(orient=\"records\")\n",
    "item_json_arr = json.loads(item_json)\n",
    "import json \n",
    "for i, j in enumerate(item_json_arr):\n",
    "    indexDocElement(esClient,response=json.dumps(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "# query = \"sport Headphones\"\n",
    "query = \"Woman Jeans\"\n",
    "\n",
    "r = requests.get('https://{}/crowdflower/crowdflower/_search?&q=product_title:{}'.format(elastic_search_endpoint,query), auth=(master_user, master_user_password))\n",
    "rjson = r.json()\n",
    "rjson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import numpy \n",
    "queries = [] \n",
    "products = []\n",
    "ids = [] \n",
    "to_transform = [] \n",
    "for i, r in enumerate(rjson['hits']['hits']): \n",
    "    print(r)\n",
    "    ids.append(r['_source']['id'])\n",
    "    queries.append(query)\n",
    "    products.append(r['_source']['product_title'])\n",
    "    to_transform.append([r['_source']['id'],r['_source']['product_title']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_query_feature =  to_q_p_bert_embeddings(queries, products)\n",
    "\n",
    "title_query_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(title_query_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(preds): \n",
    "    to_transform[i].append(p)\n",
    "    \n",
    "reranked_result = sorted(to_transform, key=lambda x:x[2], reverse=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
